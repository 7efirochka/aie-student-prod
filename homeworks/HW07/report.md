# HW07 – Report

> Файл: `homeworks/HW07/report.md`  
> Важно: не меняйте названия разделов (заголовков). Заполняйте текстом и/или вставляйте результаты.

## 1. Datasets

Вы выбрали 3 датасета из 4 (перечислите): **S07-hw-dataset-01.csv**, **S07-hw-dataset-02.csv**, **S07-hw-dataset-04.csv**

### 1.1 Dataset 1

- Файл: `S07-hw-dataset-01.csv`
- Размер: (12000, 9)
- Признаки: числовые
- Пропуски: нет
- "Подлости" датасета: нет 

### 1.2 Dataset 2

- Файл: `S07-hw-dataset-02.csv`
- Размер: (8000, 4)
- Признаки: числовые 
- Пропуски: нет 
- "Подлости" датасета: выбросы 

### 1.3 Dataset 4

- Файл: `S07-hw-dataset-04.csv`
- Размер: (10000, 33)
- Признаки: числовые, категоральные
- Пропуски: 5915, в числовых признаках, в каждом столбце ~200
- "Подлости" датасета: категоральные признаки, высокая размерность (много столбцов с числовыми признаками)

## 2. Protocol

Опишите ваш "честный" unsupervised-протокол.

- Препроцессинг (**ColunmTransformer**): 
  - Для числовых признаков (**Pipeline**):
      - `SimpleImputer` - для обработки пропусков брать среднее значение по столбцу
      - `StandardScaler` - общая стандартизация признаков
  - Для категоральных признаков (**Pipeline**):
      - `SimpleImputer` - для обработки пропусков брать использовать значение `missing`
      - `OneHotEncoder` - преобразование категоральных признаков в бинарные, но если при преобразовании данных встречается категория, которой не было при обучении, столбцы становятся 0
      
  - какой диапазон/сетка параметров для KMeans (k) и второго метода (eps/min_samples или linkage/k)
    - Для KMeans (silhouette_vs_k): **range(2, 8)**
    - Для DBSCAN (silhouette_vs_eps): **np.linspace(0.08, 4, 15)**
    - Для AgglomerativeClustering (linkage): **ward/complete** (делала вручную)

  - чем руководствовались при выборе "лучшего"
    - Везде руководствоваласт метрикой silhouette. 
    - Хотя в датасете №2, учитывала важность Davies-Bouldin в связи с особенностями датасета
- Метрики: silhouette / Davies-Bouldin / Calinski-Harabasz (и как считали для DBSCAN при наличии шума)
  - Результаты всех метрик можно увидеть в отчёте.
  - Для DBSCAN считала метрику не учитывая точки с пропущенными значениями 
- Визуализация: PCA(2D), silhouette_vs_k, silhouette_vs_eps

## 3. Models

Перечислите, какие модели сравнивали **на каждом датасете**, и какие параметры подбирали.

Минимум (для каждого датасета):

- Датасет №1
  - KMeans (`k` = 2 (поиск через **silhouette_vs_k**), `random_state` = 42, `n_init` = 15)
  - DBSCAN (`eps` = 1.5  (поиск через **silhouette_vs_eps**), `min_samples` = 5, доля шума = 0)

- Датасет №2
  - KMeans (`k` = 2 (поиск через **silhouette_vs_k**), `random_state` = 42, `n_init` = 15)
  - AgglomerativeClustering (`k` = 2, `linkage` = ward, `metric` = euclidean)

- Датасет №4
  - KMeans (`k` = 5 (поиск через **silhouette_vs_k**), `random_state` = 42, `n_init` = 15)
  - DBSCAN (`eps` = 3.3 (поиск через **silhouette_vs_eps**), `min_samples` = 5, доля шума = 0.0005)


## 4. Results

- Краткая сводка результатов и выводы представлены в отчете. С подробными метриками можно ознакомиться в файле `metrics_summary.json` 


### 4.1 Dataset 1

- Лучший метод и параметры: KMeans (`k` = 2, `random_state` = 42, `n_init` = 15)
- Метрики (silhouette / DB / CH): 
   **sihouette_score**: 0.5216395622404242,
   **davies_bouldin_score**: 0.6853295219054456,
   **calinski_harabasz_score**: 11786.954622671532
- Если был DBSCAN: 0, шума не было
- Коротко: Так как датасет это сферические кластеры, то KMeans наиболее подходящая модель

### 4.2 Dataset 2

- Лучший метод и параметры: KMeans (`k` = 2, `random_state` = 42, `n_init` = 15)
- Метрики (silhouette / DB / CH): 
    **sihouette_score**: 0.25126198673567773,
    **davies_bouldin_score**: 1.3001480229740283,
    **calinski_harabasz_score**: 2915.5877696831076
- Если был DBSCAN: -
- Коротко: Показтель DB наиболее важен в этом датасете из-за особенностей данных, поэтому выбрана модель KMeans, хотя в целом результаты обеих моделей схожи

### 4.3 Dataset 4

- Лучший метод и параметры: DBSCAN (`eps` = 3.3, `min_samples` = 5)
- Метрики (silhouette / DB / CH): 
    **sihouette_score**: 0.4481166925611092,
    **davies_bouldin_score**: 0.9754672333344209,
    **calinski_harabasz_score**: 5104.453680939717
- Если был DBSCAN: 0.0005, доля шума незначительна
- Коротко: Отличие в результатах моделей минимальны, оа метода хорошо подходят

## 5. Analysis

### 5.1 Сравнение алгоритмов (важные наблюдения)

- Где KMeans "ломается" и почему?
  - Если кластеры не сферической формы, KMeans сделано преимущественно для сферических кластеров
  - Если много выбросов, модель не может правильно определить центр, что приводит к неправильным кластерам
  - Неверно указано число кластеров, принудительно объединяет или делит кластеры, там, где это не нужно

- Где DBSCAN/иерархическая кластеризация выигрывают и почему?
  - Кластеры произвольной формы, модель ищет области, а не сферы
  - Если есть шум или выбросы, модель явно выделяет шум и выбросы
  - Умеет работать с разной плотностью, благорадя параметрам
  - Сам определяет число кластеров, не нужно знать количество кластеров заранее

- Что сильнее всего влияло на результат: 
  - Масштабирование, выбросы, плотность

### 5.2 Устойчивость (обязательно для одного датасета)

- Какую проверку устойчивости делали (5 запусков KMeans по разным seed или иной подход):
  - `random_state` : ARI_score
  - `n_clusters`: silhouette_score
- Что получилось (в 3-6 строк)
  -  Для проверки `random_state`: 
    Показатель ARI_score > 99%, что говорит о хорошей устойчивости датасета и надежности данных. Этот показатель означает, что данные распределены равномерно и модель одинакого хорошо справляется со всеми показателями.
  - Для проверка `n_clusters`: 
  Показатели silhouette_score разнятся ~0.05 единиц, это значит данные действительно имеют чёткую кластерную структуру, а значит, что модель хорошо справляется с определением кластеров.
- Вывод: Датафрейм №2 устойчив. Причины преведены выше.

### 5.3 Интерпретация кластеров

- Как вы интерпретировали кластеры:
  - Датасет №1. Модели выделили 2 (KMeans) или 3 (DBSCAN) группы данных, которые в обоих случаях хорошо разделены друг от друга. Желтый кластер является самым большим, а занчит представляет собой наиболее частые и типичные наблюдения в наборе данных. Остальные кластеры не такие большие, а значит представляют собой малую долю наблюдений. Точки шума отсутствуют.

  - Датасет №2. Эксперементальным путем было найдено, что 2 кластера - оптимальный вариант для обеих моделей. В случае с KMeans кластеры разделены чёткой линией. В случае с AgglomarativeClustering графики разделены кривой линией. По обоим графикам видно, данные кластерицированы примерно 50/50, что позволяет судить о 2 примерно одинаковых по количестку наблюдений группах. К центру данные более уплотнены, тогда как к краям плотность значительно меньше. Шума нет

  - Датасет №4. Обе модели выделили 5 кластеров причем их организация очень схожа. Все кластеры сферические, уполтненные к центру, разброса точек по краям нет. Что значит, 5 примерно одинаковых групп наблюдений, примерно равных по количеству. Шума нет.

## 6. Conclusion

4-8 коротких тезисов: чему научились про кластеризацию, метрики и корректный протокол unsupervised-эксперимента.

Кластеризация - это поиск структуры данных. Алгоритмы кластеризации позволяют выяылять скрытые группы без опоры на метки, поэтому важна структура данных. В зависимости от нее будут выбраны разные алгоритмы кластеризации, например для сферических KMeans, DBSCAN для произвольной формы и т.д.

Также важна предобработка данных, если есть пропуски, категоральные данные или данные разного масштаба - все это требует предварительной обработки перед анализом.

Основные метрики: Silhouette, Davies-Bouldin, Calinski-Harabasz, позволяют понять точность алгоритма. А есть такое как ARI-score, которые работают с истинными метками и позволяет понять истинность данных.

Unsupervised-эксперимент состоит из многих шагов, таких как: предобработка, эксперемент, тестирование, проверки стабильности и прочее.