# HW06 – Report

> Файл: `homeworks/HW06/report.md`  
> Важно: не меняйте названия разделов (заголовков). Заполняйте текстом и/или вставляйте результаты.

## 1. Dataset

- Какой датасет выбран: `S06-hw-dataset-02.csv`
- Размер: (18000, 39)
- Целевая переменная: `target` (класс 0 **73.7%**, класс 1 **26.3%** )
- Признаки: что за типы (числовые)

## 2. Protocol

- Разбиение: train/test (0.25, `random_state`)
- Подбор: CV на train (фолдов: 5)
    **Что было оптимизировано:**
    Для **DecisionTreeClassifer**:
        Подбор метрик:     `max_depth`: [ 5, 7, 10],
                           `min_samples_leaf`: [50, 100, 150]
    
    Для **RandomForestClassifier**:
        Подбор метрик:      `n_estimators`: [50, 100],
                            `max_depth`: [5, 7],
                            `min_samples_leaf`: [40, 70]

    Для **HistGradientBoostingClassifier**:
        Подбор метрик:     `max_depth`: [7, 9],
                           `min_samples_leaf`: [100, 150],
                           `learning_rate`: [0.01, 0.1]
                           
- Метрики: accuracy, precision, F1, ROC-AUC. Все эти метрики необходимы чтобы видеть общую картину работы модели

- GridSearch проводила по метрике "ROC-AUC", потому что именно она определяет насколько хорошо модель справляется с разделением классов.

## 3. Models

Опишите, какие модели сравнивали и какие гиперпараметры подбирали.

Минимум:

- DummyClassifier 

  Не подбирала гиперпараметры, указала только `strategy` = "stratified" , чтобы предсказания производились сохраняя распределение классов `target`.

- LogisticRegression (baseline из S05)

  Не подбирала гиперпараметры, оставила модель в базовой форме.

- DecisionTreeClassifier (контроль сложности: `max_depth` + `min_samples_leaf` или `ccp_alpha`)

    Подбор метрик:     `max_depth`: [ 5, 7, 10],
                       `min_samples_leaf`: [50, 100, 150]

    По GridSearchCV лучшими оказались: **{'max_depth': 10, 'min_samples_leaf': 50}**

- RandomForestClassifier

    Подбор метрик:      `n_estimators`: [50, 100],
                        `max_depth`: [5, 7],
                        `min_samples_leaf`: [40, 70]

    По GridSearchCV лучшими оказались: **{'max_depth': 7, 'min_samples_leaf': 40, 'n_estimators': 100}**

- HistGradientBoosting

    Подбор метрик:     `max_depth`: [7, 9],
                       `min_samples_leaf`: [100, 150],
                       `learning_rate`: [0.01, 0.1]
                       
    По GridSearchCV лучшими оказались: **{'learning_rate': 0.1, 'max_depth': 9, 'min_samples_leaf': 100}**

Опционально:

- StackingClassifier (с CV-логикой)

  Подбор параметров проводила вручную.
  На роль оценщиков (estimators) были выбраны:

  - `LogisticRegression`: max_iter=50, class_weight='balanced'
  - `RandomForestClassifier`: n_estimators=50, random_state=42, max_depth=5 , class_weight="balanced"
  - `AdaBoostClassifier`: n_estimators=50, random_state=42, algorithm='SAMME'

  Финальный оценщик:

    - `LogisticRegression`: max_iter=50

  Также в `StackingClassifier` был указан обязательный параметр **passthrough=False**, благодаря которому модель не может видеть итоговые y_test.

## 4. Results

- Таблица/список финальных метрик на test по всем моделям:

{
  "DummyClassifer": {
    "accuracy": 0.6208888888888889,
    "f1": 0.27404255319148935,
    "precision": 0.2756849315068493,
    "roc_auc": 0.49952573717272036
  },
  "LogisticRegress": {
    "accuracy": 0.8162222222222222,
    "f1": 0.5717244950802693,
    "precision": 0.7369826435246996,
    "roc_auc": 0.8008904412072182
  },
  "DecisionTree": {
    "accuracy": 0.8311111111111111,
    "f1": 0.6184738955823293,
    "precision": 0.7604938271604939,
    "roc_auc": 0.8480817598516628
  },
  "RandomForest": {
    "accuracy": 0.8288888888888889,
    "f1": 0.7120418848167539,
    "precision": 0.6380697050938338,
    "roc_auc": 0.8880222118190376
  },
  "HistBoost": {
    "accuracy": 0.9017777777777778,
    "f1": 0.7934579439252336,
    "precision": 0.8862212943632568,
    "roc_auc": 0.9279255641942783
  },
  "Stacking": {
    "accuracy": 0.8477777777777777,
    "f1": 0.6788560712611346,
    "precision": 0.7613038906414301,
    "roc_auc": 0.86875260717065
  }
}

Более точные данные содержаться в `artifacts/metrics_test.json`

- Победитель (по ROC-AUC или по согласованному критерию) и краткое объяснение

Победитель: **HistGradientBoostingClassifier** по критерию `ROC-AUC`

- лучшие результаты по метрике `ROC-AUC`  с результатом в почти 85%, что значит, что модель с большим успехом разделяет данные.
- лучшие результаты cv (более 92%) 
- имеет высокие результаты по другим метрикам (не менее 80%).


## 5. Analysis

- Устойчивость: что будет, если поменять `random_state` (хотя бы 5 прогонов для 1-2 моделей) – кратко

  **HistGradientBoost**: высокая устойчивость (разброс < 0.5%)

  **RandomForest**: отличная устойчивость благодаря ансамблированию (разброс < 3%)

  Вывод: модели стабильны к разным разбиениям данных

- Ошибки: confusion matrix для лучшей модели + комментарий

Confusion matrix для **HistGradientBoost**: 
[[3209  109]
 [ 333  849]]

С более подробной сonfusion matrix можно ознакомиться в `artifacts/figures/ConfusionMatrix.png`

- Интерпретация: permutation importance (top-10/15) + выводы

Сильнее всего на модель влияют признаки f16, f01, f07, f19, f23. Так как мы не знаем что скрывается за этими параметрами, то сложно сделать вывод о совпадении ожиданиям данных. Подробный график можно увидеть в файле `HW06.ipynb`

## 6. Conclusion

3-6 коротких тезисов: что вы поняли про деревья/ансамбли и про честный ML-протокол.


Деревья решений это хорошая модель для нахождения нелинейной зависимости, с которыми удобно работать за счет визуализации решений и многих настраиваемых параметров. Но они легко склонны к переобучению и хорошо подстраиваются под шум.

Ансамблирование - это мощным инструмент для улучшения работы деревьев путем совместной работы нескольких деревьев.

Баггинг - метод ансамблирования, при котором модели работают параллельно и вывод делается из усредненных полученных результатов, большой + в том, что деревья независимы, что позволяет избежать обучения на выбросах, а также обеспечивают скорейшую скорость обучения.

Бустинг - также метод ансамблирования, при котором модель обучается последовательно и запоминает ошибки предыдущих моделей, что позволяет делать меньше ошибок.

Стакинг - метод ансамблирования, при котором несколько моделей обучаются на данных, а затем их предсказания используются для финальной модели, которая и выводит итоговые выводы. Именно здесь очень важен честным ML-протокол, то есть когда модель использует Test данные только один раз, для финальной оценки. Это нужно чтобы модель не знала ответы заранее.